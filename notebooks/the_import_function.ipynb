{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/astro/phrdhx/automated_exocomet_hunt\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/astro/phrdhx/automated_exocomet_hunt\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "import kplr\n",
    "import data\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table, unique\n",
    "from astropy.stats import sigma_clip, sigma_clipped_stats\n",
    "from scipy.optimize import curve_fit\n",
    "from astropy.timeseries import LombScargle\n",
    "from analysis_tools_cython import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_lightcurve(file_path, drop_bad_points=False,\n",
    "                      ok_flags=[5]):\n",
    "    \"\"\"Returns (N by 2) table, columns are (time, flux).\n",
    "\n",
    "    Flags deemed to be OK are:\n",
    "    5 - reaction wheel zero crossing, matters for short cadence\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        hdulist = fits.open(file_path)\n",
    "    except FileNotFoundError:\n",
    "        print(\"Import failed: file not found\")\n",
    "        return\n",
    "\n",
    "    scidata = hdulist[1].data\n",
    "    if 'kplr' in file_path:\n",
    "        table = Table(scidata)['TIME','PDCSAP_FLUX','SAP_QUALITY']\n",
    "    elif 'tess' in file_path:\n",
    "        #try:\n",
    "        table = Table(scidata)['TIME','PDCSAP_FLUX','QUALITY']\n",
    "        print(len(table), \"length at import\")\n",
    "        print(type((table)['QUALITY'][0]))\n",
    "        #except:\n",
    "        #    time = scidata.TIME\n",
    "        #    flux = scidata.PDCSAP_FLUX\n",
    "        #    quality = scidata.QUALITY\n",
    "        #    table = Table([time,flux,quality],names=('TIME','PDCSAP_FLUX','QUALITY'))\n",
    "\n",
    "\n",
    "    if drop_bad_points:\n",
    "        bad_points = []\n",
    "        if 'kplr' in file_path:\n",
    "            q_ind = get_quality_indices(table['SAP_QUALITY'])\n",
    "        elif 'tess' in file_path:\n",
    "            q_ind = get_quality_indices(table['QUALITY'])\n",
    "        \n",
    "        for j,q in enumerate(q_ind): # j=index, q=quality\n",
    "            if j+1 not in ok_flags:\n",
    "                bad_points += q.tolist() # adds bad_points by value of q (the quality indices) and converts to list\n",
    "    \n",
    "\n",
    "        # bad_points = [i for i in range(len(table)) if table[i][2]>0]\n",
    "        table.remove_rows(bad_points)\n",
    "        print(len(table),\"length after drop_bad_points\")\n",
    "\n",
    "    # Delete rows containing NaN values. \n",
    "    ## if flux or time columns are NaN's, remove them.\n",
    "    nan_rows = [ i for i in range(len(table)) if\n",
    "            math.isnan(table[i][1]) or math.isnan(table[i][0]) ]\n",
    "\n",
    "    table.remove_rows(nan_rows)\n",
    "\n",
    "    # Smooth data by deleting overly 'spikey' points.\n",
    "    ## if flux - 0.5*(difference between neihbouring points) > 3*(distance between neighbouring points), spike identified\n",
    "    spikes = [ i for i in range(1,len(table)-1) if \\\n",
    "            abs(table[i][1] - 0.5*(table[i-1][1]+table[i+1][1])) \\\n",
    "            > 3*abs(table[i+1][1] - table[i-1][1])]\n",
    "\n",
    "    ## flux smoothened out by changing those points to 0.5*distance between neighbouring points\n",
    "    for i in spikes:\n",
    "        table[i][1] = 0.5*(table[i-1][1] + table[i+1][1])\n",
    "        \n",
    "    print(len(table),\"length at end\")\n",
    "\n",
    "    return table\n",
    "\n",
    "def import_XRPlightcurve(file_path,sector,clip=4,drop_bad_points=True,ok_flags=[9],return_type='astropy'):\n",
    "    \"\"\"\n",
    "    file_path: path to file\n",
    "    sector = lightcurve sector\n",
    "    drop_bad_points: Removing outlier points. Default False\n",
    "    mad_plots: plots MAD comparisons\n",
    "    q: lightcurve quality, default 0 (excludes all non-zero quality)\n",
    "    clip: Sigma to be clipped by (default 3)\n",
    "    return_type: Default 'astropy'. Pandas DataFrame also available with 'pandas' \n",
    "\n",
    "    returns\n",
    "        - table: Astropy table of lightcurve\n",
    "        - info: additional information about the lightcurve (TIC ID, RA, DEC, TESS magnitude, Camera, Chip)\n",
    "    \"\"\"\n",
    "    lc = pd.read_pickle(file_path)\n",
    "\n",
    "    for i in range(len(lc)):\n",
    "        if isinstance(lc[i], np.ndarray):\n",
    "            lc[i] = pd.Series(lc[i])\n",
    "    for_df = lc[6:]  # TIC ID, RA, DEC, TESS magnitude, Camera, Chip\n",
    "    columns = [\n",
    "        \"time\",\n",
    "        \"raw flux\",\n",
    "        \"corrected flux\",\n",
    "        \"PCA flux\",\n",
    "        \"flux error\",\n",
    "        \"quality\",\n",
    "    ]\n",
    "    df = pd.DataFrame(data=for_df).T \n",
    "    df.columns = columns\n",
    "    \n",
    "    table = Table.from_pandas(df)\n",
    "    print(len(table),\"length at import\")\n",
    "    # loading Ethan Kruse bad times\n",
    "    bad_times = data.load_bad_times()\n",
    "    bad_times = bad_times - 2457000\n",
    "    # loading MAD \n",
    "    mad_df = data.load_mad()\n",
    "    sec = sector\n",
    "    camera = lc[4]\n",
    "    mad_arr = mad_df.loc[:len(table)-1,f\"{sec}-{camera}\"]\n",
    "    sig_clip = sigma_clip(mad_arr,sigma=clip,masked=True)\n",
    "\n",
    "    # setting zero quality only\n",
    "    #table = table[table['quality'] == 0]\n",
    "\n",
    "    # applied MAD cut to keep points within selected sigma\n",
    "    #mad_cut = mad_arr.values < med_sig_clip + clip*(rms_sig_clip)\n",
    "    mad_cut = mad_arr.values < ~sig_clip.mask # --> check this one. Could it be .data?\n",
    "    print(len(mad_cut),\"length of mad cut\")\n",
    "    \n",
    "    # return indices of values above MAD threshold\n",
    "    matched_ind = np.where(~mad_cut) # indices of MAD's above threshold\n",
    "\n",
    "  # Change quality of matched indices to 2**(17-1) (or add 2**(17-1) if existing flag already present)\n",
    "    table['quality'][matched_ind] += 2**(17-1)\n",
    " \n",
    "    table['quality'] = table['quality'].astype(np.int32) # int32 set so it can work with `get_quality_indices` function\n",
    "\n",
    "    # Ethan Kruse bad time mask\n",
    "    mask = np.ones_like(table['time'], dtype=bool)\n",
    "    for i in bad_times:\n",
    "        newchunk = (table['time']<i[0])|(table['time']>i[1])\n",
    "        mask = mask & newchunk\n",
    "        \n",
    "    # Apply Kruse bad mask to table\n",
    "    table = table[mask]\n",
    "\n",
    "    if drop_bad_points:\n",
    "        bad_points = []\n",
    "        q_ind = get_quality_indices(table['quality'])\n",
    "    \n",
    "        for j,q in enumerate(q_ind): # j=index, q=quality\n",
    "            if j+1 not in ok_flags:\n",
    "                bad_points += q.tolist()\n",
    "        table.remove_rows(bad_points)\n",
    "\n",
    "        \n",
    "    # if mad_plot:\n",
    "    #     mad_plots(table=table,array=mad_arr,median=med_sig_clip,rms=rms_sig_clip,clip=clip,sector=sec,camera=camera)\n",
    "    \n",
    "    # completes masking of array elements representing non-zero flags (excludes quality flag 23; above MAD threshold values are excluded to get clean lightcurve)\n",
    "    #table = table[table['quality'] == 0] \n",
    "    \n",
    "    # Delete rows containing NaN values. \n",
    "    nan_rows = [ i for i in range(len(table)) if\n",
    "            math.isnan(table[i][2]) or math.isnan(table[i][0]) ] # -> check this \n",
    "\n",
    "    table.remove_rows(nan_rows)\n",
    "    print(len(table),\"length after drop bad points\")\n",
    "\n",
    "    # Smooth data by deleting overly 'spikey' points.\n",
    "    spikes = [ i for i in range(1,len(table)-1) if \\\n",
    "            abs(table[i][1] - 0.5*(table[i-1][1]+table[i+1][1])) \\\n",
    "            > 3*abs(table[i+1][1] - table[i-1][1])]\n",
    "\n",
    "    for i in spikes:\n",
    "        table[i][1] = 0.5*(table[i-1][1] + table[i+1][1])\n",
    "    print(len(table),\"length at end\")\n",
    "\n",
    "    if return_type == 'pandas':\n",
    "\n",
    "        return table.to_pandas(), lc[0:6]\n",
    "    else:\n",
    "\n",
    "        return table, lc[0:6]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'betapic/tesslcs_sector_6_104_2_min_cadence_targets_tesslc_270577175.pkl'\n",
    "filename_spoc = 'tess_SPOC/4112/0759/hlsp_tess-spoc_tess_phot_0000000141120759-s0006_tess_v1_lc.fits'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "993 length at import\n",
      "993 length of mad cut\n",
      "844 length after drop bad points\n",
      "844 length at end\n"
     ]
    }
   ],
   "source": [
    "table = import_XRPlightcurve(filename,6, drop_bad_points=True,ok_flags=[17])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><i>Table length=2</i>\n",
       "<table id=\"table140066550729040\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>time</th><th>raw flux</th><th>corrected flux</th><th>PCA flux</th><th>flux error</th><th>quality</th></tr></thead>\n",
       "<thead><tr><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>int32</th></tr></thead>\n",
       "<tr><td>1469.0125148958496</td><td>347161.4921875</td><td>347159.51928986365</td><td>347257.51836509426</td><td>16.086396368743504</td><td>0</td></tr>\n",
       "<tr><td>1471.700010107689</td><td>346899.203125</td><td>347069.55329667364</td><td>347039.16784235585</td><td>16.080735360786594</td><td>65536</td></tr>\n",
       "</table></div>"
      ],
      "text/plain": [
       "<Table length=2>\n",
       "       time           raw flux    ...     flux error     quality\n",
       "     float64          float64     ...      float64        int32 \n",
       "------------------ -------------- ... ------------------ -------\n",
       "1469.0125148958496 347161.4921875 ... 16.086396368743504       0\n",
       " 1471.700010107689  346899.203125 ... 16.080735360786594   65536"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique(table,keys='quality')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
